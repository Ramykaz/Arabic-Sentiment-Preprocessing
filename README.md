# Arabic Sentiment Preprocessing  

This repository contains Python scripts for **preprocessing Arabic sentiment datasets**, focusing on text cleaning, tokenization, feature extraction, and retweet network analysis. The goal is to enhance data quality for **sentiment classification models**, particularly **Convolutional Neural Networks (CNNs)** trained on word embeddings (GloVe, Skip-Gram, CBOW).  

This project was part of my **research internship under Prof. Hala Mulki** at **OrtadoÄŸu AraÅŸtÄ±rmalarÄ± Merkezi - ORSAM**. My primary contribution was **data preprocessing and analysis**, ensuring the dataset was optimized for deep learning-based sentiment classification.  

ğŸ“„ **Read the research paper:** [docs/Arabic_Sentiment_Preprocessing.pdf](docs/Arabic_Sentiment_Preprocessing.pdf)  

---

## ğŸ“‚ Project Structure  

```
Arabic-Sentiment-Preprocessing/
â”‚â”€â”€ data/                   # Raw and processed datasets
â”‚   â”œâ”€â”€ raw_data.csv        # Original dataset
â”‚   â”œâ”€â”€ cleaned_data.csv    # Preprocessed dataset
â”‚â”€â”€ notebooks/              # Jupyter Notebooks for data analysis
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb  
â”‚â”€â”€ scripts/                # Python preprocessing scripts
â”‚   â”œâ”€â”€ text_cleaning.py    # Removes stopwords, special symbols, etc.
â”‚   â”œâ”€â”€ tokenization.py     # Tokenization & normalization for Arabic text
â”‚   â”œâ”€â”€ ngram_analysis.py   # Generates n-grams & word clouds
â”‚   â”œâ”€â”€ network_analysis.py # Retweet network visualization
â”‚â”€â”€ docs/                   # Research paper & documentation
â”‚   â”œâ”€â”€ Arabic_Sentiment_Preprocessing.pdf  
â”‚â”€â”€ README.md               # Project overview
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚â”€â”€ .gitignore              # Ignore unnecessary files
```

---

## ğŸš€ Installation & Setup  

### 1ï¸âƒ£ Clone the repository  
```sh
git clone https://github.com/yourusername/Arabic-Sentiment-Preprocessing.git
cd Arabic-Sentiment-Preprocessing
```

### 2ï¸âƒ£ Install dependencies  
```sh
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run preprocessing scripts  

#### **1. Text Cleaning**  
```sh
python scripts/text_cleaning.py
```
Removes stopwords, punctuation, hashtags, and normalizes text.  

#### **2. Tokenization & Normalization**  
```sh
python scripts/tokenization.py
```
Tokenizes Arabic text, removes diacritics, and normalizes script variations.  

#### **3. N-gram Analysis & Word Cloud**  
```sh
python scripts/ngram_analysis.py
```
Extracts top unigrams/bigrams and generates word cloud visualization.  

#### **4. Retweet Network Analysis**  
```sh
python scripts/network_analysis.py
```
Builds and visualizes a retweet network graph for sentiment clustering.  

---

## ğŸ“Š Exploratory Data Analysis  

For **data visualization and insights**, open the Jupyter Notebook:  

```sh
jupyter notebook notebooks/exploratory_analysis.ipynb
```
Includes:
- Sentiment distribution graphs  
- Text length analysis  
- Word cloud visualization  

---

## ğŸ“œ Research Paper  

This project was conducted as part of my **research internship under Prof. Hala Mulki at ORSAM**. My contribution focused on **preprocessing and analyzing Arabic text data** to improve sentiment classification models.  

ğŸ“„ **Read the full paper:** [docs/Arabic_Sentiment_Preprocessing.pdf](docs/Arabic_Sentiment_Preprocessing.pdf)  

---

## ğŸ›  Dependencies  

Ensure you have the following Python libraries installed:  

```txt
pandas
numpy
nltk
matplotlib
seaborn
wordcloud
networkx
farasa
```

To install all dependencies:  
```sh
pip install -r requirements.txt
```

---

## ğŸ† Acknowledgments  

This project was part of my research under **Prof. Hala Mulki** at **OrtadoÄŸu AraÅŸtÄ±rmalarÄ± Merkezi - ORSAM**. It was a **preprocessing and data analysis task** aimed at improving sentiment classification using **deep learning models**.  

If you find this repository useful, consider **starring** â­ it on GitHub!  

---


